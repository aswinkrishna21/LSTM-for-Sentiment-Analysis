{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/sample_submission_gfvA5FD.csv\n/kaggle/input/test.csv\n/kaggle/input/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/train.csv')\ntest = pd.read_csv('/kaggle/input/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   id  label                                              tweet\n0   1      0   @user when a father is dysfunctional and is s...\n1   2      0  @user @user thanks for #lyft credit i can't us...\n2   3      0                                bihday your majesty\n3   4      0  #model   i love u take with u all the time in ...\n4   5      0             factsguide: society now    #motivation","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = train['tweet'].values\nlabels = train['label'].values\ntest_input = test['tweet'].values\ntest_label = list()","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Text PreProcessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nStopWords = stopwords.words('english')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"appos = {\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\", \"didn't\" : \"did not\", \"doesn't\" : \"does not\",\n\"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\", \"haven't\" : \"have not\", \"he'd\" : \"he would\",\n\"he'll\" : \"he will\", \"he's\" : \"he is\", \"i'd\" : \"I would\", \"i'd\" : \"I had\", \"i'll\" : \"I will\", \"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\"it's\" : \"it is\", \"it'll\":\"it will\", \"i've\" : \"I have\", \"let's\" : \"let us\", \"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\", \"shan't\" : \"shall not\", \"she'd\" : \"she would\", \"she'll\" : \"she will\", \"she's\" : \"she is\",\n\"shouldn't\" : \"should not\", \"that's\" : \"that is\", \"there's\" : \"there is\", \"they'd\" : \"they would\", \"they'll\" : \"they will\",\n\"they're\" : \"they are\", \"they've\" : \"they have\", \"we'd\" : \"we would\", \"we're\" : \"we are\", \"weren't\" : \"were not\",\n\"we've\" : \"we have\", \"what'll\" : \"what will\",\"what're\" : \"what are\",\"what's\" : \"what is\", \"what've\" : \"what have\",\n\"where's\" : \"where is\", \"who'd\" : \"who would\", \"who'll\" : \"who will\", \"who're\" : \"who are\", \"who's\" : \"who is\",\n\"who've\" : \"who have\", \"won't\" : \"will not\", \"wouldn't\" : \"would not\", \"you'd\" : \"you would\", \"you'll\" : \"you will\",\n\"you're\" : \"you are\", \"you've\" : \"you have\", \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\", \"didn't\": \"did not\"}","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from string import punctuation\ndef tweet_format(tweets):\n    all_tweets = list()\n    for text in tweets:\n        lower_case = text.lower()\n        words = lower_case.split()\n        formatted = [appos[word] if word in appos else word for word in words]\n        formatted_test = list()\n        for word in formatted:\n            if word not in StopWords:\n                formatted_test.append(word)\n        formatted = \" \".join(formatted_test)\n        punct_text = \"\".join([ch for ch in formatted if ch not in punctuation])\n        all_tweets.append(punct_text)\n    all_text = \" \".join(all_tweets)\n    all_words = all_text.split()\n    for i in range(len(all_tweets)):\n        if all_tweets[i].startswith(\"user\"):\n            all_tweets[i] = all_tweets[i].replace(\"user\", '')\n    return all_tweets, all_words","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Creating own embeddings based on the corpus**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter \n# Counts the occurence of each word\nall_tweets, all_words = tweet_format(tweets)\ncount_words = Counter(all_words)\ntotal_words = len(all_words)\nsorted_words = count_words.most_common(total_words)\nvocab_to_int = {w:i+1 for i,(w,c) in enumerate(sorted_words)}","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_tweets[0]","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"' father dysfunctional selfish drags kids dysfunction run'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_tweets(tweets):\n    '''\n    encodes review into an array\n    '''\n    All_tweets = list()\n    for text in tweets:\n        text = text.lower()\n        text = \"\".join([ch for ch in text if ch not in punctuation])\n        All_tweets.append(text)\n    encoded_tweets = list()\n    for tweet in All_tweets:\n        encoded_tweet = list()\n        for word in tweet.split():\n            if word not in vocab_to_int.keys():\n                encoded_tweet.append(0)\n            else:\n                encoded_tweet.append(vocab_to_int[word])\n        encoded_tweets.append(encoded_tweet)\n    return encoded_tweets","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pad_sequences(encoded_tweets, sequence_length = 30):\n    ''' \n    Return features of tweet_ints, where each review is padded with 0's or truncated to the input seq_length.\n    ensures all tweets have the same length\n    '''\n    features = np.zeros((len(encoded_tweets), sequence_length), dtype=int)\n    \n    for i, tweet in enumerate(encoded_tweets):\n        tweet_len = len(tweet)\n        if (tweet_len <= sequence_length):\n            zeros = list(np.zeros(sequence_length-tweet_len))\n            new = zeros + tweet\n        else:\n            new = tweet[:sequence_length]\n        features[i,:] = np.array(new)\n    return features","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(tweets):\n    \"\"\"\n    This Function will tranform reviews in to model readable form\n    \"\"\"\n    formated_tweets, all_words = tweet_format(tweets)\n    encoded_tweets = encode_tweets(formated_tweets)\n    features = pad_sequences(encoded_tweets, 30)\n    return features","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Analyzing tweet length**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_tweets = encode_tweets(tweets)\ntweet_len = [len(encoded_tweet) for encoded_tweet in encoded_tweets]\npd.Series(tweet_len).hist()\nplt.show()\npd.Series(tweet_len).describe()","execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"count    31962.000000\nmean        12.938145\nstd          5.461209\nmin          2.000000\n25%          9.000000\n50%         12.000000\n75%         17.000000\nmax         34.000000\ndtype: float64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# **Splitting the Data and Building the Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting data into 90%train and 10%validation\nfeatures = preprocess(tweets)\nx_train = features[:int(0.90 * len(features))]\ny_train = labels[:int(0.90 * len(features))]\nx_valid = features[int(0.90 * len(features)):]\ny_valid = labels[int(0.90 * len(features)):]\nprint(len(y_train), len(y_valid))","execution_count":15,"outputs":[{"output_type":"stream","text":"28765 3197\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\n\n#creating Tensor Dataset\n#torch.Tensor has default dtype float32 but from_numpy() inherits a default dtype of int32\ntrain_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\nvalid_data = TensorDataset(torch.from_numpy(x_valid), torch.from_numpy(y_valid))\n\n#data loader\nbatch_size = 64\ntrain_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, drop_last = True)\nvalid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True, drop_last = True)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#obtain one batch of training data\ndataiter = iter(train_loader)\nsample_x, sample_y = dataiter.next()\nprint('Sample input size: ', sample_x.size()) # batch_size, seq_length\nprint('Sample input: \\n', sample_x)\nprint()\nprint('Sample label size: ', sample_y.size()) # batch_size\nprint('Sample label: \\n', sample_y)","execution_count":17,"outputs":[{"output_type":"stream","text":"Sample input size:  torch.Size([64, 30])\nSample input: \n tensor([[    0,     0,     0,  ...,  6537,    54,     2],\n        [    0,     0,     0,  ...,    87,   880, 16803],\n        [    0,     0,     0,  ...,   102,    19,    82],\n        ...,\n        [    0,     0,     0,  ...,   960, 21502,   287],\n        [    0,     0,     0,  ...,    85,   306,    65],\n        [    0,     0,     0,  ..., 28491, 28492,    15]])\n\nSample label size:  torch.Size([64])\nSample label: \n tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating the LSTM class\nimport torch.nn as nn \n\nclass CustomLSTM(nn.Module):\n    '''\n    this will be the LSTM model which will be used to perform the sentiment analysis\n    '''\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob = 0.5):\n        '''\n        initialize the model by setting up the layers\n        '''\n        super().__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        #embedding and LSTM layers\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = drop_prob, batch_first = True)\n        \n        #dropout layer\n        self.dropout = nn.Dropout(0.3)\n        \n        #Linear and sigmoid layer\n        self.fc1 = nn.Linear(hidden_dim, 64)\n        self.fc2 = nn.Linear(64, 16)\n        self.fc3 = nn.Linear(16, output_size)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x, hidden):\n        '''\n        performing forward pass of our model on some input and hidden state\n        '''\n        batch_size = x.size()\n        \n        #Embedding and LSTM\n        embedd = self.embedding(x)\n        lstm_out, hidden = self.lstm(embedd, hidden)\n        \n        #stacking up lstm output\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        \n        #dropout and fully connected layers\n        out = self.dropout(lstm_out)\n        out = self.fc1(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        out = self.dropout(out)\n        out = self.fc3(out)\n        sig_out = self.sigmoid(out)\n        \n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        \n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        \"\"\"\n        Initialize Hidden STATE\n        \"\"\"\n        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n        # initialized to zero, for hidden state and cell state of LSTM\n        weight = next(self.parameters()).data\n        \n        if (train_on_gpu):\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(vocab_to_int) + 1\noutput_size = 1\nembedding_dim = 400\nhidden_dim = 256\nn_layers = 2\n\nnet = CustomLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\nprint(net)","execution_count":19,"outputs":[{"output_type":"stream","text":"CustomLSTM(\n  (embedding): Embedding(47507, 400)\n  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc1): Linear(in_features=256, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=1, bias=True)\n  (sigmoid): Sigmoid()\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss and optimization functions\nlr = 0.001\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr = lr)\n\n#checking if GPU is available\ntrain_on_gpu = torch.cuda.is_available()\n\nepochs = 5\ncounter = 0\nprint_every = 100\nclip = 5 #gradient clipping\n\nif(train_on_gpu):\n    net.cuda()\n\nnet.train()\nfor e in range(epochs):\n    #initialize the hidden state (h0, c0)\n    train_loss = []\n    h = net.init_hidden(batch_size)\n    \n    #loop through each batch\n    for inputs, labels in train_loader:\n        counter += 1\n        \n        if(train_on_gpu):\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            \n        # Creating new variables for the hidden state, otherwise we'd backprop through the entire training history\n        h = tuple([each.data for each in h])\n        \n        #sets gradients of all parameters to zero initially\n        net.zero_grad()\n        \n        output, h = net(inputs, h)\n        \n        #calculating loss and performing backprop\n        loss = criterion(output.squeeze(), labels.float())\n        train_loss.append(loss)\n        loss.backward()\n        \n        #clip_grad_norm helps prevent grad explosion\n        nn.utils.clip_grad_norm(net.parameters(), clip)\n        optimizer.step()\n        \n        #loss stats\n        if counter % print_every == 0:\n            val_h = net.init_hidden(batch_size)\n            val_losses = []\n            net.eval()\n            for inputs, labels in valid_loader:\n                \n                #creating new variables for the hidden state, otherwise  we'd backprop through the entire training history\n                val_h = tuple([each.data for each in val_h])\n                \n                inputs, labels = inputs.cuda(), labels.cuda()\n                output, val_h = net(inputs, val_h)\n                val_loss = criterion(output.squeeze(), labels.float())\n                \n                val_losses.append(val_loss.item())\n            \n            net.train()\n            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n                  \"Step: {}...\".format(counter),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))","execution_count":20,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","name":"stderr"},{"output_type":"stream","text":"Epoch: 1/5... Step: 100... Loss: 0.254657... Val Loss: 0.243587\nEpoch: 1/5... Step: 200... Loss: 0.245408... Val Loss: 0.181150\nEpoch: 1/5... Step: 300... Loss: 0.187299... Val Loss: 0.162870\nEpoch: 1/5... Step: 400... Loss: 0.121939... Val Loss: 0.148698\nEpoch: 2/5... Step: 500... Loss: 0.055599... Val Loss: 0.149855\nEpoch: 2/5... Step: 600... Loss: 0.023647... Val Loss: 0.160886\nEpoch: 2/5... Step: 700... Loss: 0.027614... Val Loss: 0.149210\nEpoch: 2/5... Step: 800... Loss: 0.111229... Val Loss: 0.154323\nEpoch: 3/5... Step: 900... Loss: 0.021073... Val Loss: 0.130737\nEpoch: 3/5... Step: 1000... Loss: 0.002213... Val Loss: 0.195183\nEpoch: 3/5... Step: 1100... Loss: 0.019400... Val Loss: 0.166082\nEpoch: 3/5... Step: 1200... Loss: 0.001922... Val Loss: 0.208097\nEpoch: 3/5... Step: 1300... Loss: 0.013425... Val Loss: 0.202327\nEpoch: 4/5... Step: 1400... Loss: 0.029879... Val Loss: 0.212110\nEpoch: 4/5... Step: 1500... Loss: 0.013186... Val Loss: 0.251458\nEpoch: 4/5... Step: 1600... Loss: 0.003535... Val Loss: 0.264761\nEpoch: 4/5... Step: 1700... Loss: 0.001582... Val Loss: 0.253466\nEpoch: 5/5... Step: 1800... Loss: 0.002897... Val Loss: 0.277805\nEpoch: 5/5... Step: 1900... Loss: 0.010546... Val Loss: 0.292192\nEpoch: 5/5... Step: 2000... Loss: 0.000980... Val Loss: 0.313102\nEpoch: 5/5... Step: 2100... Loss: 0.000955... Val Loss: 0.353130\nEpoch: 5/5... Step: 2200... Loss: 0.001900... Val Loss: 0.327568\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(test_input):\n    output_list = list()\n    batch_size = 64\n    net.eval()\n    with torch.no_grad():\n        test_tweet = preprocess(test_input)\n        for tweet in test_tweet:\n            #convert to tensor to pass into the model\n            feature_tensor = torch.from_numpy(tweet).view(1, -1)\n            if(train_on_gpu):\n                feature_tensor = feature_tensor.cuda()\n            batch_size = feature_tensor.size(0)\n            #initialize hidden state\n            h = net.init_hidden(batch_size)\n            #get the output from the model\n            output, h = net(feature_tensor, h)\n            pred = torch.round(output.squeeze())\n            output_list.append(pred)\n        test_labels = [int(i.data.cpu().numpy()) for i in output_list]\n        return test_labels","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = test_model(test_input)","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame()\noutput['id'] = test['id']\noutput['label'] = test_labels","execution_count":75,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output","execution_count":76,"outputs":[{"output_type":"execute_result","execution_count":76,"data":{"text/plain":"          id  label\n0      31963      0\n1      31964      0\n2      31965      0\n3      31966      0\n4      31967      0\n...      ...    ...\n17192  49155      1\n17193  49156      0\n17194  49157      0\n17195  49158      0\n17196  49159      0\n\n[17197 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31963</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31964</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31965</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31966</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31967</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17192</th>\n      <td>49155</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17193</th>\n      <td>49156</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17194</th>\n      <td>49157</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17195</th>\n      <td>49158</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17196</th>\n      <td>49159</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17197 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","execution_count":77,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}